{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music_emotion_recognition_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ageroul/music_emotion_recognition_cnn/blob/main/music_emotion_recognition_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4fQGR6hZmb5"
      },
      "source": [
        "# Code for classification experiments (A, B,and part of C) with Deep Neural Networks\n",
        "as described in paper wit title \"Emotion recognition in music using deep neural networks\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpciIldeDPoc"
      },
      "source": [
        "# import libraries and packages installation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYbJhV3nzpDs"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsKKAA2xf3W2"
      },
      "source": [
        "!pip install torch-lr-finder "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5BVLwhztRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66003e35-6b1f-4577-ad3b-623935cfd5bd"
      },
      "source": [
        "from __future__ import print_function \n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from  torch.utils.data import WeightedRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics  import confusion_matrix\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "import PIL.Image as Image\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
        "try:            \n",
        "  from torch_lr_finder import torch_lr_finder\n",
        "except ImportError:\n",
        "  import sys \n",
        "  sys.path.insert(0, '..')\n",
        "  from torch_lr_finder import LRFinder    \n",
        "\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch Version:  1.8.1+cu101\n",
            "Torchvision Version:  0.9.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp2kmgM3pu_o"
      },
      "source": [
        "# Input parameters\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWeuZuPBGMKY"
      },
      "source": [
        "These are the basic parameters that we adjust each time in order to:\n",
        "\n",
        "\n",
        "1.   **data_dir** -  Load the appropriate set (big-set or 360-set) \n",
        "\n",
        "1.   **model_name** - Select the architecture to run the classification task\n",
        "\n",
        "1.   **workers** - Select the appropriate number of workers of the dataloader which means the number of processes running in parallel to create the batches. In our experiments our choice was 2 workers as the overhead on Colab's GPU was prohibitive for using more\n",
        "2.   **num_classes** - The number of classes where the default is 3 for those tasks that have three classes (valence, energy, tension) and 5 for the emotion classification (anger, fear, happy, sad, tender)\n",
        "\n",
        "\n",
        "5.   **batch_size** - the number of samples produced in each batch.\n",
        "32 was the maximum allowed value for the algorithms to work without any problems due to Colab's GPU memory limits\n",
        "\n",
        "\n",
        "6.   **num_epochs** - All trainings were run for 20 epochs for consistency of the experiments\n",
        "\n",
        "\n",
        "7.   **feature_extract** - Boolean selection for the type of Transfer Learning to be used: If TRUE, only the weights of the classifier are updated, if FALSE it is used to fine-tune pre-trained weights of all network layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGy-rcpT0F_2"
      },
      "source": [
        "The CNN architectures used in the experiments are listed below:\n",
        "\n",
        "*   ResNeXt-101-32x8d\n",
        "*   Alexnet\n",
        "\n",
        "\n",
        "*   VGG16_bn\n",
        "\n",
        "*   Squeezenet 1.0\n",
        "*   Densenet 121\n",
        "\n",
        "\n",
        "*   Inception v3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG4pa0NgztOe"
      },
      "source": [
        "\n",
        "data_dir = \"/content/drive/MyDrive/styleGAN2-train&val\"\n",
        "\n",
        "# CNN architectures[resnext, alexnet, vgg, squeezenet, densenet, inception]\n",
        "model_name = \"alexnet\"\n",
        "# 2 workers σε όλα τα πειράματα με το Colab\n",
        "workers = 2\n",
        "# Task dependent number: \"emotions\" has  5 classes, all ohers 3 classes\n",
        "num_classes = 3\n",
        "# fixed batch size (32)\n",
        "batch_size = 32\n",
        "# all models were trained for 20 epochs\n",
        "num_epochs = 20\n",
        "# boolean for transfer learning type\n",
        "feature_extract = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB-p4FQbqu9t"
      },
      "source": [
        "# Helper functions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npso3zp5GRj1"
      },
      "source": [
        "The train_model function handles the training and validation phases and has the following inputs:\n",
        "\n",
        "\n",
        "*   **model** - The selected model for training\n",
        "\n",
        "*   **dataloaders** - the class of torch.utils.data that helps to organize and shuffle the sample mini-batches\n",
        "\n",
        "*   **criterion** - the cost function (we have chosen CrossEntropyLoss)\n",
        "\n",
        "*   **optimizer** - The optimization function (we have chosen SGD with momentum)\n",
        "*   **scheduler** - Function that reduces the learning rate when a selected metric stops improving, we used ReduceLROnPlateau\n",
        "\n",
        "\n",
        "*   **is_inception** - Boolean for the Inception v3 model as its architecture has two outputs and the losses take both into account\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9b16m9GztL1"
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "    epoch_loss_tr = []\n",
        "    epoch_acc_tr = []\n",
        "    epoch_loss_val = [] \n",
        "    epoch_acc_val = []\n",
        "\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "       \n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  \n",
        "            else:\n",
        "                model.eval()   \n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            predicted_labels = []\n",
        "            true_labels = []\n",
        "           \n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                \n",
        "                # resetting the gradients of the current batch\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward propagation during training\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Especially for Inception whice because of its 2 outputs\n",
        "                    # in the train phase we add them up in order to calculate the error\n",
        "                    if is_inception and phase == 'train':\n",
        "# From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    #   while in the test phase we only take into account the final output.\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        true_labels.extend(labels.cpu().numpy()) \n",
        "\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    predicted_labels.extend(preds.cpu().numpy()) \n",
        "\n",
        "                    \n",
        "                    if phase == 'train':\n",
        "                    # Gradient calculation                     \n",
        "                        loss.backward()\n",
        "                    # backpropagation\n",
        "                        optimizer.step()\n",
        "              \n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "            if phase == 'train':\n",
        "                  epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "                  epoch_loss_tr.append(epoch_loss)\n",
        "                  epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "                  epoch_acc_tr.append(epoch_acc)\n",
        "                  print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "                  \n",
        "            else:\n",
        "                  \n",
        "                  epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "                  epoch_loss_val.append(epoch_loss)\n",
        "                  epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "                  epoch_acc_val.append(epoch_acc)\n",
        "                  # scheduler operation according to the values of epoch loss\n",
        "                  scheduler.step(epoch_loss) \n",
        "                  print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "                  print('Learning rate at this epoch is:', optimizer_ft.param_groups[0]['lr'])\n",
        "\n",
        "            # keeping the best model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                # classification report from scikit learn\n",
        "                print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
        "\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "    \n",
        "    # loading best model\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, epoch_loss_tr, epoch_acc_tr,epoch_loss_val, \\\n",
        "           epoch_acc_val, predicted_labels, true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIL71gm9q7ud"
      },
      "source": [
        "The **set_parameter_requires_grad** function is called when we need to \"freeze\" some layers of the network. That is, we stop calculating gradients with param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDsn_oNy08wp"
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwzRxl4MDa7Y"
      },
      "source": [
        "# Initialization of the selected Networks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdZBg0NaGVST"
      },
      "source": [
        "The initialize_model function takes as arguments the name of the model, the number of classes, the type of transfer learning and whether the selected model will be pre-trained. Each architecture requires different handling and configuration of its output(s). (Experiment A)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bssGXzcztJN"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnext\":\n",
        "        \"\"\" ResNext101_32x8d\n",
        "        \"\"\"\n",
        "        model_ft = models.resnext101_32x8d(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG16_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg16_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3 \n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialization of the model\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibDZBj-ilSk7"
      },
      "source": [
        "\n",
        "\n",
        "For the models we have pre-trained in Big-set and 360-set for Energy, Valence. (Experiment B)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uiwoO3pkklY"
      },
      "source": [
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if model_name == \"resnext\":\n",
        "        \"\"\" ResNext101_32x8d\n",
        "        \"\"\"\n",
        "        model_ft = models.resnext101_32x8d()\n",
        "        # pre-trained in big-set & 360-set (Energy,Valence)\n",
        "        model_ft = torch.load('path of the appropriate .pt file')\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet()\n",
        "        # pre-trained in big-set & 360-set (Energy,Valence)\n",
        "        model_ft = torch.load('path of the appropriate .pt file')\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG16_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg16_bn()\n",
        "        # pre-trained in big-set & 360-set (Energy,Valence)\n",
        "        model_ft = torch.load('path of the appropriate .pt file')\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0()\n",
        "        # pre-trained in big-set & 360-set (Energy,Valence)\n",
        "        model_ft = torch.load('path of the appropriate .pt file')\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121()\n",
        "        # pre-trained in big-set & 360-set (Energy,Valence)\n",
        "        model_ft = torch.load('path of the appropriate .pt file')\n",
        "\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes) \n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3 \n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3()\n",
        "        # pre-trained in big-set & 360-set (Energy,Valence)\n",
        "        model_ft = torch.load('path of the appropriate .pt file')\n",
        "\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "    \n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialization of the model\n",
        "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
        "\n",
        "\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSEi6Mp-DgmU"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-AT1_CybUiU"
      },
      "source": [
        "# Data augmentation, class imbalance handling\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAxJKFgcVbgz"
      },
      "source": [
        "Using the torchvision.transforms library we proceed to some transformations of the images (the mel-spectrograms) that lead to an augmentation of the training data to avoid overfitting especially when there is a small number of samples to be trained. On the validation data we only perform normalization:  \n",
        "\n",
        "*   **RandomResizedCrop** - crop the image to random size (from 0.08-1.0) and aspect ratio (3/4 to 4/3\n",
        "*   **RandomHorizontalFlip** - flips the image horizontally with a predefined probability (p=0.5)\n",
        "\n",
        "\n",
        "*   **Resize** - Changes the dimensions of the input image to the desired dimensions (input_size)\n",
        "\n",
        "\n",
        "*   **ToTensor** - Before normalization we convert the image to tensor\n",
        "*    **Normalize** - Each tensor is normalized around a specified set of mean and normal distribution. (Avoiding the exploding gradient problem if the values stray to sizes beyond the 0-1 limit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_WO7tDSWWQ1"
      },
      "source": [
        "WeightedRandomSampler is used to ensure that each batch of data contains samples of all classes in proportion.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOOSDuhPbXJe"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create train - val sets\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "# The class_to_idx method returns the class names in numbers (id's) e.g. 0,1,2,3 \n",
        "image_datasets['train'].class_to_idx\n",
        "# idx2class performs the reverse process from class_to_idx\n",
        "idx2class = {v: k for k, v in image_datasets['train'].class_to_idx.items()}\n",
        "\n",
        "# The function for getting the distribution of classes in the dataset\n",
        "def get_class_distribution_train(dataset_obj):\n",
        "  count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "  for element in dataset_obj: \n",
        "    y_lbl = element[1] \n",
        "    y_lbl = idx2class[y_lbl]      \n",
        "    count_dict[y_lbl] += 1\n",
        "  return count_dict\n",
        "print(\"Distribution of classes in train set: \\n\", get_class_distribution_train(image_datasets['train']))\n",
        "\n",
        "target_list = torch.tensor(image_datasets['train'].targets)\n",
        "class_count = [i for i in get_class_distribution_train(image_datasets['train']).values()]\n",
        "\n",
        "# class weights calculation\n",
        "class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
        "print(class_weights)\n",
        "\n",
        "# Weights per class assigned to all samples \n",
        "class_weights_all = class_weights[target_list]\n",
        "print(class_weights_all)\n",
        "\n",
        "# Passing weights and number of samples to WeightedRandomSampler\n",
        "sampler_train = WeightedRandomSampler(class_weights_all, \\\n",
        "                num_samples = len(class_weights_all), replacement=True)\n",
        "\n",
        "# Passing the Sampler to the train set's dataloader\n",
        "dataloader_train = torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, \\\n",
        "                   shuffle=False, sampler=sampler_train, num_workers=workers)\n",
        "dataloader_val = torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, \\\n",
        "                 shuffle=True, num_workers=workers)\n",
        "\n",
        "\n",
        "dataloaders_dict = {'train': dataloader_train, 'val':dataloader_val}\n",
        "\n",
        "class_names = image_datasets['train'].classes\n",
        "print(image_datasets['val'].class_to_idx)\n",
        "print(image_datasets['val'].classes)\n",
        "print(len(image_datasets['val']))\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Usr0_8arNeMq"
      },
      "source": [
        "# Saving the weights for future use in the next classifications of the corresponding set\n",
        "#torch.save(class_weights_all, 'weights to save as pt files')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5z24gwswpZo"
      },
      "source": [
        "# loading class weights\n",
        "class_weights_all_saved = torch.load('path to the appropriate weight file (pt)')\n",
        "class_weights_all_saved"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2amIjidAewUf"
      },
      "source": [
        "Since the weights of the classes have been computed in the 1st classification task and are stored they do not need to be recalculated , therefore:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wP2y4MOxHcr"
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(input_size),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(input_size),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "sampler_train = WeightedRandomSampler(class_weights_all_saved, \\\n",
        "                num_samples = len(class_weights_all_saved), replacement=True)\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=False, \\\n",
        "                   sampler=sampler_train, num_workers=workers)\n",
        "dataloader_val = torch.utils.data.DataLoader(image_datasets['val'], batch_size=batch_size, shuffle=True,\\\n",
        "                 num_workers=workers)\n",
        "dataloaders_dict = {'train': dataloader_train, 'val':dataloader_val}\n",
        "class_names = image_datasets['train'].classes\n",
        "print(image_datasets['val'].class_to_idx)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guY8920oEHnD"
      },
      "source": [
        "# Sending to GPU and Optimization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Txs1gk4ohCu"
      },
      "source": [
        "The model is driven to the GPU and depending on the type of training we have already selected, the corresponding parameters are updated. So, if the selection is to fine-tune the model the list of parameters to be printed will be long (depending on the size of the model). If the option is to update only the classifier weights then the list of parameters will be short, showing only the classifier layer parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4SxX-Xkz8O2"
      },
      "source": [
        " # Send the model to GPU\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHcQE-0T6TfS"
      },
      "source": [
        "The optimization algorithm we used in all experiments is the Stochastic Gradient Descent with Momentum (SGD). The optimization of the learning rate is achieved with the help of the LRFinder tool where exponentially and in 100 iterations it finds the ideal training rate starting from a value of 0.001 to 1.0. Also, the ReduceOnPlateau scheduler lowers the rate if the loss value does not drop every 3 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufqSktIn6FVK"
      },
      "source": [
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "scheduler = ReduceLROnPlateau(optimizer_ft, patience=3,  mode='min')\n",
        "##### learning rate finder: https://github.com/davidtvs/pytorch-lr-finder\n",
        "lr_finder = LRFinder(model_ft, optimizer_ft, criterion = nn.CrossEntropyLoss(), device=\"cuda\") \n",
        "lr_finder.range_test(dataloaders_dict['val'], end_lr=1, num_iter=100, step_mode=\"exp\")    \n",
        "lr_finder.plot()                 \n",
        "print(optimizer_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_xZDbYnWqbm"
      },
      "source": [
        " Resetting the lr_finder in order to avoid that its test values (to find the ideal learning rate) are involved in the backpropagation, according to the instructions of the developers of the utility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6JcshYJja_d"
      },
      "source": [
        "lr_finder.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClrHWIcgsgix"
      },
      "source": [
        "Applying the value of the training rate as estimated above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31v4Tojpysjx"
      },
      "source": [
        "model_ft = model_ft.to(device)\n",
        "\n",
        "params_to_update = model_ft.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)\n",
        "# After finding the ideal value of the learning rate from lr_finder we place it here\n",
        "optimizer_ft = optim.SGD(params_to_update, lr= 0.001, momentum=0.9)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer_ft, patience=3,  mode='min')\n",
        "print(optimizer_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8pgKI4-r-XB"
      },
      "source": [
        "# Visualization\n",
        "With imshow function we display the images (Mel-Spectrograms) of a batch  from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iy_kwb8H0cL"
      },
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjhPDNefH0ZP"
      },
      "source": [
        "inputs, classes = next(iter(dataloaders_dict['train']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7HF-GsXH0V8"
      },
      "source": [
        "out = torchvision.utils.make_grid(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGlK9TnRIGjR"
      },
      "source": [
        "imshow(out, title=[class_names[x] for x in classes])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gndyJK58u4Nh"
      },
      "source": [
        "# Starting the training of the network\n",
        "We call the **train_model** function which starts the training and validation process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdNA8uWgz8L-"
      },
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model_ft, val_acc_history, epoch_loss_tr, epoch_acc_tr,epoch_loss_val, epoch_acc_val,\\\n",
        "predicted_labels, true_labels = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft,\\\n",
        "                                scheduler, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sokDGoWiI2gk"
      },
      "source": [
        "# Model Visualization\n",
        "We call the visualize_model function to visualize the validation model so that it displays 4 Mel-Spectrograms on the screen each time we call it. The spectrograms are labeled with both the actual and the prediction label.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fivfqwyLGdh"
      },
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    plt.rcParams['axes.grid'] = False \n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels,) in enumerate(dataloaders_dict['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            for j in range(inputs.shape[0]):\n",
        "                images_so_far += 1\n",
        "                print('ground truth: {}'.format(class_names[labels[j]]))\n",
        "                ax = plt.subplot(2, num_images//2, images_so_far)\n",
        "                ax.axis('equal')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                X = inputs.cpu().data[j]\n",
        "                imshow(X)\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return \n",
        "        model.train(mode=was_training)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-avTaoHYeWC-"
      },
      "source": [
        "visualize_model(model_ft, 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75pkRX2cOaNB"
      },
      "source": [
        "# Loss and accuracy plots\n",
        "Using the package matplotlib we display the plots of the loss and accuracy of the model in relation to the training epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QUZJji0DHWJ"
      },
      "source": [
        "plt.title(\"Val & Train Loss\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(range(1,num_epochs+1),epoch_loss_val,label=\"Validation loss\")\n",
        "plt.plot(range(1,num_epochs+1),epoch_loss_tr,label=\"Training loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Smsl9odtfEb"
      },
      "source": [
        "plt.title(\"Val & Train Accuracy\")\n",
        "plt.xlabel(\"Training Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.plot(range(1,num_epochs+1), epoch_acc_val, label=\"Validation accuracy\")\n",
        "plt.plot(range(1,num_epochs+1), epoch_acc_tr, label=\"Training accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVOND6sNOiZI"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ho-cTcGrvcwo"
      },
      "source": [
        "# Predictions (Classification Report & Confusion Matrix)\n",
        "By using the sklearn.metrics package we create the classification report and the confusion matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wknW0dtouM5Z"
      },
      "source": [
        "First, with the function get_predictions we get the model predictions (y_pred) and the actual values in order to become inputs to sklearn's classification report & confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCeyusGo103B"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  predictions = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloaders_dict['val']:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.as_tensor(predictions).cpu()\n",
        "  real_values = torch.as_tensor(real_values).cpu()\n",
        "  return predictions, real_values\n",
        "\n",
        "y_pred, y_test = get_predictions(model_ft, dataloaders_dict['val'].dataset)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToSNpO9j7nsP"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix, class_names):\n",
        "  cm = confusion_matrix.copy()\n",
        "  cell_counts = cm.flatten()\n",
        "  cm_row_norm = cm /cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "  row_percentages = [\"{0:.2f}\".format(value) for value in cm_row_norm.flatten()]\n",
        "\n",
        "  cell_labels = [f\"{cnt}\\n{per}\" for cnt, per in zip(cell_counts, row_percentages)]\n",
        "  cell_labels = np.asarray(cell_labels).reshape(cm.shape[0], cm.shape[1])\n",
        "\n",
        "  df_cm = pd.DataFrame(cm_row_norm, index=class_names, columns=class_names)\n",
        "\n",
        "  hmap = sns.heatmap(df_cm, annot=cell_labels, fmt=\"\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True labels')\n",
        "  plt.xlabel('Predicted labels');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-JOd_Wf7cZ-"
      },
      "source": [
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "show_confusion_matrix(cm,class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA0BJyV42RVt"
      },
      "source": [
        "# Save and recall the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F0UXiUeEsoq"
      },
      "source": [
        "The model after the necessary adjustments, for improving the quality of training, is stored so that it can be used in the future on a new, unknown set in order to classify it.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k414JIXo_7gJ"
      },
      "source": [
        "#torch.save(model_ft, 'path to the appropriate pt file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb4yzfwcC1oK"
      },
      "source": [
        " #test_load = torch.load('path to the appropriate pt file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4JnJDcyQ-H8"
      },
      "source": [
        "# Classifying an unknown set (test set)\n",
        "Once the trained model has been saved we can recall it and make a prediction on a new set. The steps are similar as before during the validation set prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB0OwhBSPyF6"
      },
      "source": [
        "# input_size = 224 for all, except inception 299\n",
        "new_input_size = 224\n",
        "test_set_dir = 'path to the test set'\n",
        "pretrained_model = 'path to the appropriate .pt file'\n",
        "test_load = torch.load(pretrained_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8VELasbJHvU"
      },
      "source": [
        "data_transforms = {\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(new_input_size),\n",
        "        transforms.CenterCrop(new_input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(\"Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "image_datasets = {'test': datasets.ImageFolder(test_set_dir, data_transforms['test'])}\n",
        "dataloader_test = torch.utils.data.DataLoader(image_datasets['test'], batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "class_names = image_datasets['test'].classes\n",
        "print(image_datasets['test'].class_to_idx)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgdksnNBQ-H-"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = test_load\n",
        "  predictions = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in dataloader_test:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "      predictions.extend(preds)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.as_tensor(predictions).cpu()\n",
        "  real_values = torch.as_tensor(real_values).cpu()\n",
        "  return predictions, real_values\n",
        "\n",
        "y_pred, y_test = get_predictions(test_load, dataloader_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTdIlBFFQ-H_"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix, class_names):\n",
        "  cm = confusion_matrix.copy()\n",
        "  cell_counts = cm.flatten()\n",
        "  cm_row_norm = cm /cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "  row_percentages = [\"{0:.2f}\".format(value) for value in cm_row_norm.flatten()]\n",
        "\n",
        "  cell_labels = [f\"{cnt}\\n{per}\" for cnt, per in zip(cell_counts, row_percentages)]\n",
        "  cell_labels = np.asarray(cell_labels).reshape(cm.shape[0], cm.shape[1])\n",
        "\n",
        "  df_cm = pd.DataFrame(cm_row_norm, index=class_names, columns=class_names)\n",
        "\n",
        "  hmap = sns.heatmap(df_cm, annot=cell_labels, fmt=\"\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True labels')\n",
        "  plt.xlabel('Predicted labels');\n",
        "cm=confusion_matrix(y_test,y_pred)\n",
        "show_confusion_matrix(cm,class_names)\n",
        "print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCFLvgyXqMNL"
      },
      "source": [
        "# Prediction of a single mel-spectrogram\n",
        "With the following code we can, after recalling the model we trained, to see the class prediction with probability rates on a new, unknown image (mel-spectrogram)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLZXNMl2La7K"
      },
      "source": [
        "# input_size = 224 for all, except inception 299\n",
        "new_input_size = 224\n",
        "# test_set_dir = 'path to the test set'\n",
        "pretrained_model = 'path to the appropriate .pt file'\n",
        "test_load = torch.load(pretrained_model)\n",
        "test_load.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snAARaWUKNFx"
      },
      "source": [
        "data_transforms = {\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize(new_input_size),\n",
        "        transforms.CenterCrop(new_input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSylhnVCx9A-"
      },
      "source": [
        "def predict_proba(model, image_path):\n",
        "  img = Image.open(image_path)\n",
        "  img = img.convert('RGB')\n",
        "  img = data_transforms['test'](img).unsqueeze(0)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  pred = model(img.to(device))\n",
        "  return pred.detach().cpu().numpy().flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuJbhp6YB0Gr"
      },
      "source": [
        "pred = predict_proba(test_load, 'path to a single spectrogram image')\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjpConVHqUv-"
      },
      "source": [
        "def show_prediction_confidence(prediction, class_names):\n",
        "  pred_df = pd.DataFrame({\n",
        "    'class_names': class_names,\n",
        "    'values': prediction\n",
        "  })\n",
        "  sns.barplot(x='values', y='class_names', data=pred_df, orient='h')\n",
        "  plt.xlim([0, 1]);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR2Cl1v4Uh_f"
      },
      "source": [
        "### emotions - choose from\n",
        "class_names = ['anger', 'fear', 'happy', 'sad', 'tender']\n",
        "### energy or tension - choose from\n",
        "# class_names = ['high', 'low', 'medium']\n",
        "### valence - choose from\n",
        "# class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg34n2En2EEL"
      },
      "source": [
        "show_prediction_confidence(pred, class_names_emotions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tK6Ozx1UvEG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}